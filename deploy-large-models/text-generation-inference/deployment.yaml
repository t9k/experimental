apiVersion: apps/v1
kind: Deployment
metadata:
 name: huggingface-text-generation-inference
spec:
 replicas: 1
 selector:
   matchLabels:
     app: huggingface-text-generation-inference
 template:
   metadata:
     labels:
       app: huggingface-text-generation-inference
   spec:
     nodeName: sm02
     containers:
     - name: server
       image: ghcr.io/huggingface/text-generation-inference:0.8
       ports:
         - containerPort: 80
       args:
         - --model-id=/data/llama-7b
         - --num-shard=1
       resources:
         limits:
           cpu: 4
           memory: 64Gi
           nvidia.com/gpu: 1
       volumeMounts:
         - mountPath: /data
           name: data
         - mountPath: /dev/shm
           name: dshm
     volumes:
       - name: data
         persistentVolumeClaim:
           claimName: chat
       - name: dshm
         emptyDir:
           medium: Memory
